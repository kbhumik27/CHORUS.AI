{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988a21e6-ad16-4be1-91d3-438632844f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH]\n",
      "                             [--max_files MAX_FILES] [--seq_length SEQ_LENGTH]\n",
      "                             [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--num_workers NUM_WORKERS]\n",
      "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ue7a5adbf8d5127b839fde345138342d/.local/share/jupyter/runtime/kernel-190721db-f7a2-4717-afa6-379c61893fe6.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import datetime\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from tensorflow.python.framework import config\n",
    "\n",
    "# Intel CPU optimizations using standard TensorFlow\n",
    "config.set_visible_devices([], 'GPU')  # Disable GPU for Intel CPU optimization\n",
    "\n",
    "# Enable OneDNN optimizations (built into standard TF)\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "\n",
    "class NSynthDataLoader:\n",
    "    def __init__(self, data_path: str, max_files: int = 1000, num_workers: int = 4):\n",
    "        self.data_path = os.path.join(data_path, \"nsynth-train\")\n",
    "        self.max_files = max_files\n",
    "        self.num_workers = num_workers\n",
    "        self.metadata = {}\n",
    "        self._load_metadata()\n",
    "        \n",
    "    def _load_metadata(self):\n",
    "        metadata_path = os.path.join(self.data_path, \"examples.json\")\n",
    "        if not os.path.exists(metadata_path):\n",
    "            raise FileNotFoundError(f\"Metadata file not found at {metadata_path}\")\n",
    "        \n",
    "        print(f\"Loading metadata from {metadata_path}\")\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        print(f\"Loaded metadata for {len(self.metadata)} samples\")\n",
    "    \n",
    "    def extract_features(self, y: np.ndarray, sr: int) -> np.ndarray:\n",
    "        # Validate input audio\n",
    "        if y.shape[0] == 0:\n",
    "            raise ValueError(\"Empty audio input\")\n",
    "        \n",
    "        # Intel-optimized feature extraction\n",
    "        with tf.device('/CPU:0'):\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "            mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            mel_mean = np.mean(mel_db, axis=1)\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "            contrast_mean = np.mean(contrast, axis=1)\n",
    "\n",
    "            features = np.concatenate([mel_mean, mfccs_mean, contrast_mean])\n",
    "        \n",
    "        # Validate extracted features\n",
    "        if np.any(np.isnan(features)) or np.any(np.isinf(features)):\n",
    "            raise ValueError(\"Invalid features detected (NaN or Inf values)\")\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def _process_file(self, wav_file):\n",
    "        try:\n",
    "            file_id = wav_file.split('.')[0]\n",
    "            if file_id not in self.metadata:\n",
    "                return None, None\n",
    "            \n",
    "            audio_path = os.path.join(self.data_path, \"audio\")\n",
    "            y, sr = librosa.load(os.path.join(audio_path, wav_file), sr=16000, duration=4.0)\n",
    "            \n",
    "            # Validate audio data\n",
    "            if len(y) < sr * 0.5:  # Ensure at least 0.5 seconds of audio\n",
    "                return None, None\n",
    "                \n",
    "            features = self.extract_features(y, sr)\n",
    "            \n",
    "            metadata = self.metadata[file_id]\n",
    "            sample_params = [\n",
    "                float(metadata['pitch']) / 127.0,\n",
    "                float(metadata['velocity']) / 127.0,\n",
    "                float(metadata['instrument_family']) / 11.0,\n",
    "                float(metadata['instrument_source']) / 3.0\n",
    "            ]\n",
    "            \n",
    "            return sample_params, features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {wav_file}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def load_data(self):\n",
    "        sample_data, audio_features = [], []\n",
    "        audio_path = os.path.join(self.data_path, \"audio\")\n",
    "        wav_files = [f for f in os.listdir(audio_path) if f.endswith('.wav')]\n",
    "        \n",
    "        # Randomly shuffle the list of files\n",
    "        random.shuffle(wav_files)\n",
    "        wav_files = wav_files[:self.max_files]\n",
    "        \n",
    "        print(f\"Processing {len(wav_files)} files with {self.num_workers} workers\")\n",
    "        \n",
    "        # Parallel processing with Intel optimizations\n",
    "        with multiprocessing.Pool(processes=self.num_workers) as pool:\n",
    "            results = pool.map(self._process_file, wav_files)\n",
    "        \n",
    "        # Filter out None results and separate data\n",
    "        for sample, feature in results:\n",
    "            if sample is not None and feature is not None:\n",
    "                sample_data.append(sample)\n",
    "                audio_features.append(feature)\n",
    "        \n",
    "        print(f\"Successfully processed {len(sample_data)} files\")\n",
    "        return np.array(sample_data), np.array(audio_features)\n",
    "\n",
    "class NSynthSequencePreparation:\n",
    "    def __init__(self, seq_length: int = 32):\n",
    "        self.seq_length = seq_length\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_dims = None\n",
    "    \n",
    "    def validate_scaler(self, data):\n",
    "        \"\"\"Validate scaler transformation\"\"\"\n",
    "        transformed = self.scaler.transform(data)\n",
    "        if np.any(np.isnan(transformed)) or np.any(np.isinf(transformed)):\n",
    "            raise ValueError(\"Invalid scaling detected (NaN or Inf values)\")\n",
    "        return transformed\n",
    "\n",
    "    def prepare_data(self, sample_data, audio_features):\n",
    "        if len(sample_data) != len(audio_features):\n",
    "            raise ValueError(\"Mismatched sample and feature lengths\")\n",
    "            \n",
    "        combined_data = np.concatenate([sample_data, audio_features], axis=1)\n",
    "        self.feature_dims = combined_data.shape[1]\n",
    "        \n",
    "        # Fit the scaler to the combined data\n",
    "        self.scaler.fit(combined_data)\n",
    "        combined_data = self.validate_scaler(combined_data)\n",
    "        \n",
    "        # Use optimized NumPy operations for sequence creation\n",
    "        sequences, targets = [], []\n",
    "        for i in range(len(combined_data) - self.seq_length):\n",
    "            sequences.append(combined_data[i:i + self.seq_length])\n",
    "            targets.append(combined_data[i + self.seq_length])\n",
    "        \n",
    "        return np.array(sequences), np.array(targets)\n",
    "    \n",
    "    def save_scaler(self, path: str):\n",
    "        \"\"\"Save the fitted scaler and feature dimensions\"\"\"\n",
    "        if not hasattr(self.scaler, 'mean_'):\n",
    "            raise ValueError(\"Scaler has not been fitted to data\")\n",
    "            \n",
    "        scaler_data = {\n",
    "            'scaler': self.scaler,\n",
    "            'feature_dims': self.feature_dims\n",
    "        }\n",
    "        \n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(scaler_data, f)\n",
    "        print(f\"Scaler saved to {path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_scaler(path: str):\n",
    "        \"\"\"Load and validate saved scaler\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            scaler_data = pickle.load(f)\n",
    "            \n",
    "        if not isinstance(scaler_data, dict) or 'scaler' not in scaler_data:\n",
    "            raise ValueError(\"Invalid scaler file format\")\n",
    "            \n",
    "        return scaler_data['scaler'], scaler_data['feature_dims']\n",
    "\n",
    "def create_model(input_shape, output_shape):\n",
    "    # Use TensorFlow optimized for Intel CPUs\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First LSTM layer - optimized for CPU\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(512, return_sequences=True, \n",
    "                          implementation=2)  # Implementation 2 is faster on CPU\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(512, implementation=2)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)\n",
    "    \n",
    "    # Dense layers with appropriate kernel initializers\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', \n",
    "                            kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', \n",
    "                            kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(output_shape, activation='linear')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_data, val_targets):\n",
    "    \"\"\"Validate model predictions\"\"\"\n",
    "    predictions = model.predict(val_data, batch_size=64)\n",
    "    mse = np.mean((predictions - val_targets) ** 2)\n",
    "    print(f\"Validation MSE: {mse}\")\n",
    "    return mse < 2.0  # Threshold based on your specific needs\n",
    "\n",
    "def main(data_path='nsynth_small', \n",
    "         max_files=70000, \n",
    "         seq_length=32, \n",
    "         batch_size=64, \n",
    "         epochs=10, \n",
    "         num_workers=4,\n",
    "         checkpoint_dir='./checkpoints'):\n",
    "    \"\"\"\n",
    "    Main function with parameters that can be called directly in a Jupyter notebook\n",
    "    \"\"\"\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Configure Intel optimizations\n",
    "    print(\"Configuring Intel optimizations...\")\n",
    "    os.environ['KMP_BLOCKTIME'] = '1'\n",
    "    os.environ['KMP_SETTINGS'] = '1'\n",
    "    os.environ['KMP_AFFINITY'] = 'granularity=fine,verbose,compact,1,0'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(multiprocessing.cpu_count())\n",
    "    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "    \n",
    "    # Initialize components\n",
    "    data_loader = NSynthDataLoader(data_path, max_files=max_files, num_workers=num_workers)\n",
    "    sequence_prep = NSynthSequencePreparation(seq_length=seq_length)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    print(\"Loading data...\")\n",
    "    sample_data, audio_features = data_loader.load_data()\n",
    "    print(\"Preparing sequences...\")\n",
    "    x, y = sequence_prep.prepare_data(sample_data, audio_features)\n",
    "    \n",
    "    # Split data\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Save scaler\n",
    "    sequence_prep.save_scaler(os.path.join(checkpoint_dir, 'scaler.pkl'))\n",
    "    \n",
    "    # Create and compile model\n",
    "    print(\"Creating model...\")\n",
    "    model = create_model(\n",
    "        input_shape=(x.shape[1], x.shape[2]), \n",
    "        output_shape=y.shape[1]\n",
    "    )\n",
    "    \n",
    "    # Standard optimizer with good defaults for Intel CPUs\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.Huber(),\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, 'model_checkpoint-{epoch:02d}.h5'),\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        TensorBoard(\n",
    "            log_dir=os.path.join(checkpoint_dir, 'logs'),\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        workers=num_workers,\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    # Validate final model\n",
    "    print(\"Validating model...\")\n",
    "    if validate_model(model, x_val, y_val):\n",
    "        print(\"Model validation successful\")\n",
    "        model.save(os.path.join(checkpoint_dir, 'nsynth_model_final.h5'))\n",
    "        \n",
    "        # Save training history\n",
    "        with open(os.path.join(checkpoint_dir, 'training_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title('Model Loss During Training')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(checkpoint_dir, 'training_history.png'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Model validation failed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # If running as a script, use argparse\n",
    "    try:\n",
    "        parser = argparse.ArgumentParser(description='NSynth audio model training on Intel Tiber Cloud')\n",
    "        parser.add_argument('--data_path', type=str, default='nsynth_small', help='Path to NSynth dataset')\n",
    "        parser.add_argument('--max_files', type=int, default=70000, help='Maximum number of files to process')\n",
    "        parser.add_argument('--seq_length', type=int, default=32, help='Sequence length for LSTM')\n",
    "        parser.add_argument('--batch_size', type=int, default=64, help='Training batch size')\n",
    "        parser.add_argument('--epochs', type=int, default=10, help='Number of training epochs')\n",
    "        parser.add_argument('--num_workers', type=int, default=4, help='Number of worker processes for data loading')\n",
    "        parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory to save checkpoints')\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        main(\n",
    "            data_path=args.data_path,\n",
    "            max_files=args.max_files,\n",
    "            seq_length=args.seq_length,\n",
    "            batch_size=args.batch_size,\n",
    "            epochs=args.epochs,\n",
    "            num_workers=args.num_workers,\n",
    "            checkpoint_dir=args.checkpoint_dir\n",
    "        )\n",
    "    except SystemExit:\n",
    "        # Running in Jupyter notebook, parameters will be provided directly to main()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77a4bd-1da5-4117-9ed1-9758803d823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Intel optimizations...\n",
      "Loading metadata from nsynth_small/nsynth-train/examples.json\n",
      "Loaded metadata for 289205 samples\n",
      "Loading data...\n",
      "Processing 902 files with 8 workers\n"
     ]
    }
   ],
   "source": [
    "# Configure paths and parameters for your environment\n",
    "main(\n",
    "    data_path='nsynth_small',  # Update with your actual dataset path\n",
    "    max_files=10000,  # Start with a smaller number for testing\n",
    "    seq_length=32,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    num_workers=8,  # Adjust based on your CPU cores\n",
    "    checkpoint_dir='./nsynth_checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724cf43-bca7-4fdc-838b-3848dcf8e138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
